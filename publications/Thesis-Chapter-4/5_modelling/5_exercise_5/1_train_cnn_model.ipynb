{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CNN Model Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T12:57:53.346252900Z",
     "start_time": "2023-11-01T12:57:53.315006100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from tensorflow_addons.callbacks import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(name=f\"data/models/eval/predict\", exist_ok=True)\n",
    "os.makedirs(name=f\"data/models/eval/metrics\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 750\n",
    "CONV_LAYERS = 1\n",
    "CONV_KERNELS = {1: 19}\n",
    "CONV_KERNEL_SIZES = {1: 69}\n",
    "DENSE_LAYERS = 4\n",
    "DENSE_UNITS = {\n",
    "    1: 114,\n",
    "    2: 126,\n",
    "    3: 162,\n",
    "    4: 86,\n",
    "}\n",
    "DENSE_DROPOUT = {\n",
    "    1: 0.205,\n",
    "    2: 0.310,\n",
    "    3: 0.310,\n",
    "}\n",
    "REG_BETA = 0.021\n",
    "LEARNING_RATE = 0.0002876038\n",
    "MIN_LEARNING_RATE = 0.05 * LEARNING_RATE\n",
    "BATCH_SIZE = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessed data\n",
    "df = pd.read_pickle(\"data/preprocessed_data/CNN/dataset.pkl\").query(\"subsequent_flag_1 == 0\")\n",
    "\n",
    "with open(f\"data/preprocessed_data/CNN/columns.pkl\", \"rb\") as file:\n",
    "    y_col, x_cols = pickle.load(file)\n",
    "df_cal = df.query(\"partition in ('train', 'validation') and train_partition == 'calibration'\")\n",
    "df_tune = df.query(\"partition in ('train', 'validation') and train_partition == 'tunning'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    input_dims: int,\n",
    "    conv_layers: int,\n",
    "    conv_kernels: dict,\n",
    "    conv_kernel_sizes: dict,\n",
    "    dense_layers: int,\n",
    "    dense_units: dict,\n",
    "    dense_dropout: dict,\n",
    "    reg_beta: float,\n",
    "    learning_rate: float,\n",
    "    random_seed: int = None\n",
    ") -> tf.keras.models.Sequential:\n",
    "\n",
    "    # clear keras session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # weights L2 regularization (all layers)\n",
    "    kernel_reg = tf.keras.regularizers.l2(reg_beta)\n",
    "\n",
    "    # weights initialisation (all layers)\n",
    "    kernel_init = tf.keras.initializers.he_normal(seed=random_seed)\n",
    "\n",
    "    # model architecture\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    if conv_layers > 0:\n",
    "        model.add(\n",
    "            tf.keras.layers.Reshape(\n",
    "                name=\"input\",\n",
    "                target_shape=(input_dims, 1),\n",
    "                input_shape=(input_dims,)\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        model.add(\n",
    "            tf.keras.layers.Input(\n",
    "                name=\"input\",\n",
    "                shape=(input_dims,),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # convolutional layers\n",
    "    for layer in range(1, conv_layers+1):\n",
    "        model.add(\n",
    "            tf.keras.layers.Conv1D(\n",
    "                name=f\"conv1d_{layer}\",\n",
    "                filters=conv_kernels[layer],\n",
    "                kernel_size=conv_kernel_sizes[layer],\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                kernel_initializer=kernel_init,\n",
    "                kernel_regularizer=kernel_reg,\n",
    "                activation=\"elu\",\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            tf.keras.layers.BatchNormalization(\n",
    "                name=f\"batchnorm_{layer}\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # flatter layer\n",
    "    if conv_layers > 0:\n",
    "        model.add(\n",
    "            tf.keras.layers.Flatten(\n",
    "                name=\"flatten\"\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # dense layers\n",
    "    for layer in range(1, dense_layers+1):\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                name=f\"dense_{layer}\",\n",
    "                units=dense_units[layer],\n",
    "                kernel_initializer=kernel_init,\n",
    "                kernel_regularizer=kernel_reg,\n",
    "                activation=\"elu\"\n",
    "            )\n",
    "        )\n",
    "        if layer != dense_layers:\n",
    "            model.add(\n",
    "                tf.keras.layers.Dropout(\n",
    "                    name=f\"dropout_{layer}\",\n",
    "                    rate=dense_dropout[layer]\n",
    "                    \n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # output layer\n",
    "    model.add(     \n",
    "        tf.keras.layers.Dense(\n",
    "            name=\"output\",\n",
    "            units=1,\n",
    "            kernel_initializer=kernel_init,\n",
    "            kernel_regularizer=kernel_reg,\n",
    "            activation=\"linear\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mse\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_callbacks( \n",
    "    lr_min: float, \n",
    ") -> list:\n",
    "    \n",
    "    callbacks = []\n",
    "    \n",
    "    # reduce learning rate dynamically\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        patience=25,\n",
    "        factor=0.5,\n",
    "        min_lr=lr_min,\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0\n",
    "    )\n",
    "    callbacks.append(reduce_lr)\n",
    "\n",
    "    # early stopping criteria\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-4,  \n",
    "        patience=50,\n",
    "        mode=\"min\",\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "    callbacks.append(early_stopping)\n",
    "\n",
    "    # progress bar during training\n",
    "    progress_bar = TQDMProgressBar(show_epoch_progress=False)\n",
    "    callbacks.append(progress_bar)\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"Calculate SEP, RMSE, Bias, and RPD of predictions\n",
    "\n",
    "    \"\"\"\n",
    "    n = y_true.shape[0]\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    y_error = y_true - y_pred\n",
    "    mean_error = np.mean(y_error)\n",
    "    std_error = np.sqrt(np.square(y_error - mean_error).sum() / (n-1))\n",
    "    std_true = np.sqrt(np.square(y_true - y_true.mean()).sum() / (n-1))\n",
    "    return {\n",
    "        # number of samples\n",
    "        \"n\": len(y_true),\n",
    "        \n",
    "        # calculate r-squared (R2)\n",
    "        \"r2\": r2_score(y_true, y_pred),\n",
    "\n",
    "        # calculate root mean square error (RMSE)\n",
    "        \"rmse\": rmse,\n",
    "\n",
    "        # calculate standard error of prediction (SEP)\n",
    "        \"sep\": std_error,\n",
    "\n",
    "        # calculate bias\n",
    "        \"bias\": mean_error,\n",
    "\n",
    "        # calculate ratio of performance to deviation (RPD)\n",
    "        \"rpd\": std_true / std_error,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets = {\n",
    "    \"training\": \"partition in ('train', 'validation')\",\n",
    "    \"training_calibration\": \"partition in ('train', 'validation') and train_partition == 'calibration'\",\n",
    "    \"training_tuning\": \"partition in ('train', 'validation') and train_partition == 'tunning'\",\n",
    "    \"holdout\": \"partition == 'holdout'\",\n",
    "    \"season 2020\": \"season == 2020\",\n",
    "    \"season 2021\": \"season == 2021\",\n",
    "    \n",
    "}\n",
    "\n",
    "all_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 18:19:20.787442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.806323: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.806445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.808187: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.808284: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.808381: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.887578: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.887679: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.887738: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-05 18:19:20.887785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14373 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/user/Documents/jeremy/research-dl-nirs/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Training:   0%|           0/750 ETA: ?s,  ?epochs/s2024-04-05 18:19:22.285425: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-04-05 18:19:22.961436: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3a45b61eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-05 18:19:22.961454: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Ti Laptop GPU, Compute Capability 8.6\n",
      "2024-04-05 18:19:22.964499: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1712305163.003267  476003 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Training:  61%|██████     457/750 ETA: 11:50s,   2.43s/epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2219/2219 [==============================] - 5s 2ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_set, query \u001b[38;5;129;01min\u001b[39;00m test_sets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     43\u001b[0m     test_partition \u001b[38;5;241m=\u001b[39m df_pred\u001b[38;5;241m.\u001b[39mquery(query)\n\u001b[0;32m---> 44\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_partition\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_partition\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn_rs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_set\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m test_set\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      9\u001b[0m std_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msquare(y_error \u001b[38;5;241m-\u001b[39m mean_error)\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     10\u001b[0m std_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msquare(y_true \u001b[38;5;241m-\u001b[39m y_true\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m (n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# number of samples\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(y_true),\n\u001b[1;32m     14\u001b[0m     \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# calculate r-squared (R2)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mr2_score(y_true, y_pred),\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# calculate root mean square error (RMSE)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: rmse,\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# calculate standard error of prediction (SEP)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msep\u001b[39m\u001b[38;5;124m\"\u001b[39m: std_error,\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# calculate bias\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_error,\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# calculate ratio of performance to deviation (RPD)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrpd\u001b[39m\u001b[38;5;124m\"\u001b[39m: std_true \u001b[38;5;241m/\u001b[39m std_error,\n\u001b[1;32m     29\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "for random_seed in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    # model initialization and compile\n",
    "    model = create_model(\n",
    "        input_dims=len(x_cols),\n",
    "        conv_layers=CONV_LAYERS,\n",
    "        conv_kernels=CONV_KERNELS,\n",
    "        conv_kernel_sizes=CONV_KERNEL_SIZES,\n",
    "        dense_layers=DENSE_LAYERS,\n",
    "        dense_units=DENSE_UNITS,\n",
    "        dense_dropout=DENSE_DROPOUT,\n",
    "        reg_beta=REG_BETA,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        random_seed=random_seed\n",
    "    )\n",
    "\n",
    "    # define callbacks\n",
    "    callbacks = create_callbacks(\n",
    "        lr_min=MIN_LEARNING_RATE,\n",
    "    )\n",
    "\n",
    "    # train model \n",
    "    history = model.fit(\n",
    "        x=df_cal[x_cols],\n",
    "        y=df_cal[y_col],\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        validation_data=(df_tune[x_cols], df_tune[y_col]),\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # save model\n",
    "    model.save(f\"data/models/eval/cnn_rs{random_seed}.model.keras\")\n",
    "    \n",
    "    # make and save predictions\n",
    "    df_pred = df.copy()\n",
    "    df_pred[\"y_true\"] = df_pred[\"dry_matter\"]\n",
    "    df_pred[\"y_pred\"] = model.predict(df[x_cols])\n",
    "    df_pred.to_pickle(f\"data/models/eval/predict/cnn_rs{random_seed}.pkl\")\n",
    "    \n",
    "    \n",
    "    for test_set, query in test_sets.items():\n",
    "        test_partition = df_pred.query(query)\n",
    "        metrics = calculate_metrics(\n",
    "            y_true=test_partition[\"y_true\"], \n",
    "            y_pred=test_partition[\"y_pred\"]\n",
    "        )\n",
    "        metrics[\"model\"] = f\"cnn_rs{random_seed}\"\n",
    "        metrics[\"test_set\"] = test_set\n",
    "        metrics[\"query\"] = query\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    metrics = pd.DataFrame(all_metrics)\n",
    "    metrics.to_csv(f\"data/models/eval/metrics/cnn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>r2</th>\n",
       "      <th>rmse</th>\n",
       "      <th>sep</th>\n",
       "      <th>bias</th>\n",
       "      <th>rpd</th>\n",
       "      <th>model</th>\n",
       "      <th>test_set</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68009</td>\n",
       "      <td>0.940978</td>\n",
       "      <td>0.597824</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>4.116359</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>training</td>\n",
       "      <td>partition in ('train', 'validation')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54341</td>\n",
       "      <td>0.944249</td>\n",
       "      <td>0.584888</td>\n",
       "      <td>0.584691</td>\n",
       "      <td>0.015366</td>\n",
       "      <td>4.236648</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>training_calibration</td>\n",
       "      <td>partition in ('train', 'validation') and train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13668</td>\n",
       "      <td>0.927058</td>\n",
       "      <td>0.646703</td>\n",
       "      <td>0.645938</td>\n",
       "      <td>-0.031920</td>\n",
       "      <td>3.707163</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>training_tuning</td>\n",
       "      <td>partition in ('train', 'validation') and train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2996</td>\n",
       "      <td>0.781441</td>\n",
       "      <td>1.156253</td>\n",
       "      <td>1.148372</td>\n",
       "      <td>-0.136399</td>\n",
       "      <td>2.154062</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>holdout</td>\n",
       "      <td>partition == 'holdout'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2594</td>\n",
       "      <td>0.788733</td>\n",
       "      <td>1.111861</td>\n",
       "      <td>1.100313</td>\n",
       "      <td>-0.161283</td>\n",
       "      <td>2.198883</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>season 2020</td>\n",
       "      <td>season == 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>402</td>\n",
       "      <td>0.659543</td>\n",
       "      <td>1.409480</td>\n",
       "      <td>1.411029</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>1.714086</td>\n",
       "      <td>cnn_rs1</td>\n",
       "      <td>season 2021</td>\n",
       "      <td>season == 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n        r2      rmse       sep      bias       rpd    model  \\\n",
       "0  68009  0.940978  0.597824  0.597800  0.005863  4.116359  cnn_rs1   \n",
       "1  54341  0.944249  0.584888  0.584691  0.015366  4.236648  cnn_rs1   \n",
       "2  13668  0.927058  0.646703  0.645938 -0.031920  3.707163  cnn_rs1   \n",
       "3   2996  0.781441  1.156253  1.148372 -0.136399  2.154062  cnn_rs1   \n",
       "4   2594  0.788733  1.111861  1.100313 -0.161283  2.198883  cnn_rs1   \n",
       "5    402  0.659543  1.409480  1.411029  0.024171  1.714086  cnn_rs1   \n",
       "\n",
       "               test_set                                              query  \n",
       "0              training               partition in ('train', 'validation')  \n",
       "1  training_calibration  partition in ('train', 'validation') and train...  \n",
       "2       training_tuning  partition in ('train', 'validation') and train...  \n",
       "3               holdout                             partition == 'holdout'  \n",
       "4           season 2020                                     season == 2020  \n",
       "5           season 2021                                     season == 2021  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
